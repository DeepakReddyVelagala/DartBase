\contentsline {section}{\numberline {1}Introduction}{2}{section.1}%
\contentsline {section}{\numberline {2}Input Representation}{2}{section.2}%
\contentsline {subsection}{\numberline {2.1}TF-IDF scheme}{2}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Formulation}{2}{subsubsection.2.1.1}%
\contentsline {subsubsection}{\numberline {2.1.2}Limitation}{2}{subsubsection.2.1.2}%
\contentsline {subsection}{\numberline {2.2}SVD - text representation}{3}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Formulation}{3}{subsubsection.2.2.1}%
\contentsline {subsection}{\numberline {2.3}LDA - text representation(incomplete)}{3}{subsection.2.3}%
\contentsline {subsubsection}{\numberline {2.3.1}Formulation}{3}{subsubsection.2.3.1}%
\contentsline {subsubsection}{\numberline {2.3.2}Mathematical Formulation}{3}{subsubsection.2.3.2}%
\contentsline {subsection}{\numberline {2.4}Word2Vec}{4}{subsection.2.4}%
\contentsline {subsubsection}{\numberline {2.4.1}Continuous Bag of Words (CBOW)}{4}{subsubsection.2.4.1}%
\contentsline {subsubsection}{\numberline {2.4.2}SkipGram}{6}{subsubsection.2.4.2}%
\contentsline {subsubsection}{\numberline {2.4.3}Negative Sampling}{7}{subsubsection.2.4.3}%
\contentsline {subsection}{\numberline {2.5}GloVe}{8}{subsection.2.5}%
\contentsline {subsubsection}{\numberline {2.5.1}Formulation}{8}{subsubsection.2.5.1}%
\contentsline {subsubsection}{\numberline {2.5.2}Embeddings reflect Social bias}{9}{subsubsection.2.5.2}%
\contentsline {subsubsection}{\numberline {2.5.3}Identifying and quantifying bias in embeddings}{9}{subsubsection.2.5.3}%
\contentsline {subsection}{\numberline {2.6}FastText}{10}{subsection.2.6}%
\contentsline {subsubsection}{\numberline {2.6.1}Formulation}{10}{subsubsection.2.6.1}%
\contentsline {subsection}{\numberline {2.7}Summary - GloVe, Word2Vec, FastText}{11}{subsection.2.7}%
\contentsline {section}{\numberline {3}Language Modelling and Smoothing}{11}{section.3}%
\contentsline {subsection}{\numberline {3.1}N-gram models}{12}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Smoothing techniques for LMs}{13}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}Add-One Smoothing}{13}{subsubsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.2}Add-k Smoothing}{13}{subsubsection.3.2.2}%
\contentsline {subsubsection}{\numberline {3.2.3}Backoff}{14}{subsubsection.3.2.3}%
\contentsline {subsubsection}{\numberline {3.2.4}Interpolation}{14}{subsubsection.3.2.4}%
\contentsline {subsubsection}{\numberline {3.2.5}Absolute Discounting}{15}{subsubsection.3.2.5}%
\contentsline {subsubsection}{\numberline {3.2.6}Kneser-Ney discounting}{16}{subsubsection.3.2.6}%
\contentsline {subsubsection}{\numberline {3.2.7}Good-Turing Smoothing}{16}{subsubsection.3.2.7}%
\contentsline {section}{\numberline {4}Discourse in NLP}{17}{section.4}%
